---
author: "Oliver Speer"
date: "10.12.2024"
---

::::: columns
::: {.column width="50%"}
![ ](zlm.jpeg){width=40%}
:::

::: {.column width="50%"}
```{r version number, echo=FALSE, eval=TRUE, message=FALSE, warning=FALSE}
cat("Version:\n",format(file.info("DataUnderstanding.qmd")$mtime,"%d. %B %Y"))
```
:::
:::::

# Data Understanding {.unnumbered}

## Sammeln von Anfangsdaten {.justify}

### Protein-Elektrophorese-Daten {.justify}

Aus dem lokalen Datenserver (Phoresis / Sebia) können die Protein-Elektrophorese-Daten im csv-Format exportiert werden.

### Patientendaten {.justify}

Falls benötigt könnten über die Tagesnummer (TaNu) weitere Patientendaten, wie Geburtsdatum, Geschlecht, weitere Laborbefunde aus dem Laborinformationssystem abgerufen & hinzugefügt werden.


## Beschreiben der Daten: Qualität & Quantität {.justify}

### Protein-Elektrophorese Daten

```{r, echo=FALSE, message=FALSE, warning=FALSE}
source("StartUp.R")
StartUpRoutine()
```

```{r read csv, echo=FALSE, message=FALSE, warning=FALSE}
# Einlesen der Daten

EPcsv <- read_csv2("epcdatawithcurve.csv", col_select = c(1:4, 6), col_types = "icccc") |> 
  rename_with(~ c("ID", "TaNu", "Bef.EP", "Bef.ImFix", "curve"))
#str(EPcsv)
```


```{r skimEPdata, echo=TRUE, eval=TRUE,message=FALSE, warning=FALSE}
#| label: tbl-skimEPdata
#| tbl-cap: Datenüberblick
# print(head(EPcsv, 10))
# print(glimpse(EPcsv))
my_skim <- skim_with(base = sfl(
  #Datentyp = skim_type,
  #Variable = skim_variable,
  fehlend = n_missing,
  komplett = n_complete,
  n = length
))
ft <-  flextable(my_skim(EPcsv))|> 
  set_header_labels(skim_type = "Datentyp",
                    skim_variable = "Variable",
                    n_missing = "Fehlende Werte",
                    n = "Anzahl",
                    numeric.mean = "Mittelwert",
                    numeric.sd = "Standardabweichung",
                    numeric.p25 = "25%-Quantil",
                    numeric.p50 = "50%-Quantil",
                    numeric.p75 = "75%-Quantil",
                    numeric.p0 = "Minimum",
                    numeric.p100 = "Maximum",
                    numeric.hist = "Histogramm",
                    factor.n_unique =" Anzahl Faktoren") |>
  autofit() |>
  bold(part = "header") |>
  align(align = "center", part = "all")
ft
```

**Erklärungen:**

[\$TaNu:]{.underline} Eineindeutige Tages-Nummer (TaNu) des Auftrags. Mit ihr können auch Patientendaten und weitere Resultate zugeordnet werden. Automatisch bei Auftragserfassung vergeben, sind immer vorhanden. <br> Fehlende Daten: `r sum(is.na(EPcsv$TaNu))`

[\$Bef.EP:]{.underline} String-Daten, Befundtexte / Interpretationen, die von Labormitarbeitenden zu den Chromatogrammen manuell erstellt wurden. Diese Text enthalten wiederkehrende Formulierungen wie z. Bsp. "unauffällig", "unauffällige Charakterisitik", oder auch "M-Protein nachweisbar", "Fraktion erhöht", "Fraktion vermindert". Diese sind jedoch nicht standardisiert, kommen in vielen Varianten vor inkl Tippfehlern. <br> Fehlende Daten: `r sum(is.na(EPcsv$Bef.EP))` 

[\$Bef.ImFix:]{.underline} Befundtexte / Interpretationen, die von Labormitareitern zu den Immunfixationen (falls vorhanden) erstellt wurden. Auch hier werden ähnliche Formulierungen verwendet wie bei der EP-Befundung. Diese sind jedoch nicht standardisiert, kommen in vielen Varianten vor inkl Tippfehlern.<br> Fehlende Daten: `r sum(is.na(EPcsv$Bef.ImFix))`

[\$curve:]{.underline} Sebia speichert die Protein-Elektrophorese-Daten im hexadecimalen Format [@chenLightweightOpenSource2022]. <br>  Je String 1200 Stellen, also 300 Hexadezimalwerte. Nach Konversion ins Dezimal-System sind das also 300 Datenpunkte pro Chromatogramm.  
Bei zwei Chromatogrammen fallen die Zeichenketten auf, da sie mit "X" beginnen, Es ist fraglich ob diese tatsächlich hexadecimal sind. Diese werden hier untersucht:
```{r, echo=TRUE, message=FALSE, warning=FALSE}
hex.string <- EPcsv$curve[EPcsv$ID == 2701]

# entfernen der "X" am Anfang
hex.string <- gsub("X", "", hex.string)
# Split the string into hexadecimal parts
hex.parts <- substring(hex.string, seq(1, nchar(hex.string), 4), seq(4, nchar(hex.string), 4))

# Convert each hex part to decimal
decimal.values <- sapply(hex.parts, function(x) as.integer(paste0("0x", x)))

# dataframe with hexadecimal and decimal values
dat <- as.data.frame(decimal.values)
dat$decimal.values <- rev(dat$decimal.values)
#dat$hex.parts <- hex.parts
dat$ID <- seq_len( nrow(dat) )

# delete rows with decimal values >10000
# dat <- dat[dat$decimal.values < 10000,]

# plot(decimal.values ~ ID, data = dat, type = "l", col = "blue", lwd = 2, xlab = "ID", ylab = "signal", main = "")
```

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
#| label: fig-raw-chromatogram-plot-2700-2701
#| fig-cap: "Rohdaten zweier Protein-Elektrophorese, die offensichtlich nicht nach der SOP aufgezeichnet wurden"
# Vorbereitung der Daten für beide IDs
fun.prep.EP.data <- function(id) {
  hex.string <- EPcsv$curve[EPcsv$ID == id]
  
  # Entfernen der "X" am Anfang
  hex.string <- gsub("X", "", hex.string)
  
  # Aufteilen des Strings in 4-stellige Hexadezimalwerte
  hex.parts <- substring(hex.string, seq(1, nchar(hex.string), 4), seq(4, nchar(hex.string), 4))
  
  # Konvertierung von Hexadezimal in Dezimal
  decimal.values <- sapply(hex.parts, function(x) as.integer(paste0("0x", x)))
  
  # Erstellen eines Dataframes
  dat <- data.frame(
    ID = seq_len(length(decimal.values)),
    decimal.values = rev(decimal.values)
  )
  
  return(dat)
}




# Daten für ID 2700 und 2701 vorbereiten
dat_2700 <- fun.prep.EP.data(2700)
dat_2701 <- fun.prep.EP.data(2701)

# Plots nebeneinander darstellen
par(mfrow = c(1, 2)) # Layout für 2 Plots nebeneinander

# Plot für ID 2700
plot(decimal.values ~ ID, data = dat_2700, type = "l", col = "blue", lwd = 2, 
     xlab = "ID", ylab = "Signal", main = "ID 2700")

# Plot für ID 2701
plot(decimal.values ~ ID, data = dat_2701, type = "l", col = "blue", lwd = 2, 
     xlab = "ID", ylab = "Signal", main = "ID 2701")

# Layout zurücksetzen
par(mfrow = c(1, 1))


```
Wie weiter unten zu erkennen sein wird, fallen beide Chromatogramme durch fast 20 fach höhere Signale auf, ausserdem fehlen die Sebia-typischen Marker Peaks (s.u.). Es ist nicht ganz klar, mit welchen Einstellungen am Gerät diese Chromatogramme aufgezeichnet wurden. Daher sollten sie bei der "Data Preparation" nicht berücksichtigt werden.

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: fig-raw-chromatogram-plot-ID2
#| fig-cap: "Rohdaten einer Protein-Elektrophorese"

dat <- fun.prep.EP.data(2)

plot(decimal.values ~ ID, data = dat, type = "n", xlab = "ID", ylab = "signal", main = "")
points(dat$ID, dat$decimal.values, 
       col = ifelse(dat$decimal.values > 10000, "red", "blue"), 
       pch = 16)
```
Im Sebia Manual wird beschrieben, dass Markerpeaks an definierten Punkten eingesetzt werden um die verschiedenen Chromatogramm-Bereiche voneinander abzugrenzen. Diese sind in der oberen Abbildung als rote "Aussreisser" Punkte zu sehen.

```{r, echo=TRUE, eval=TRUE, message=FALSE, warning=FALSE}
#| label: fig-raw-chromatogram-plot-ID1675
#| fig-cap: "Rohdaten einer pathologischen Protein-Elektrophorese mit Peakbezeichnungen"
 
#library(pracma)

# Daten für ID 1675 vorbereiten
dat <- fun.prep.EP.data(1675)

# Find peaks
peaks <- findpeaks(dat$decimal.values, npeaks = 15, nups = 1, ndowns = 0, minpeakheight = 80)

# Plot
plot(decimal.values ~ ID, data = dat, type = "l", col = "blue", lwd = 2, xlab = "ID", ylab = "signal", main = " " )
points(dat$ID[peaks[,2]], peaks[,1], col = "red", pch = 20)
abline(v = dat$ID[peaks[, 3]], col = "blue", lty = 2)  # Start of peaks
abline(v = dat$ID[peaks[, 4]], col = "blue", lty = 2)  # End of peaks
abline(v = dat$ID[160], col = "orange", lty = 2)
text(x = dat$ID[peaks[, 2]], y = peaks[, 1]+c(-500, -1000, 1, -1000, 200, -1000, 200, -1000, 1, -1000, 1, -1000 ), labels = c("Albumin", "M", "alpha 1", "M", "alpha 2", "M", "beta 1", "M", "beta 2", "M",  "gamma", "M"),
     pos = c(2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 2), offset = 0.5  , col = "darkgreen")





```

Diese artifiziellen Marker Peaks sind keine echten Messsignale, daher werden diese bei der Data Preparation nicht berücksichtigt. 
Sie erschweren die Erkennung der tatsächlichen Peaks und der weiteren Features. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#| label: fig-diverse-chromatogram-plot
#| fig-cap: "Verschieden EP-Elektrophorese-Chromatogramme"


fun.prep.EP.plot <- function(id) {
  # Daten vorbereiten
  dat <- fun.prep.EP.data(id)
  
  # Entfernen von Werten > 10000
  dat <- dat[dat$decimal.values < 10000,]
  
  # Peaks finden
  #peaks <- findpeaks(dat$decimal.values, npeaks = 15, nups = 1, ndowns = 0, minpeakheight = 80)
  
  # Plot erstellen
  plot(decimal.values ~ ID, data = dat, type = "l", col = "blue", lwd = 2,
       xlab = "ID", ylab = "Signal", main = paste("ID:", id))
  points(dat$ID[peaks[,2]], peaks[,1], col = "red", pch = 20) # Peaks markieren
}

# Liste der IDs
chromatogram_ids <- c(1691, 24965, 3697, 9075, 22310, 15055, 4662, 9173, 
                      2705, 2334, 7498, 8951, 3849, 3479, 5066, 29056)

# Alle Daten in einem Dataframe kombinieren, einschließlich Peaks
all_data <- do.call(rbind, lapply(chromatogram_ids, function(id) {
  dat <- fun.prep.EP.data(id)
  dat <- dat[dat$decimal.values < 10000,]
  
  # Peaks finden
  peaks <- findpeaks(dat$decimal.values, npeaks = 15, nups = 1, ndowns = 0, minpeakheight = 80)
  
  # Speichern der Peak-Informationen
  if (!is.null(peaks)) {
    peak_data <- data.frame(
      ID = dat$ID[peaks[, 2]],
      decimal.values = peaks[, 1],
      ID_label = paste("ID:", id),
      is_peak = TRUE
    )
    dat$ID_label <- paste("ID:", id)
    dat <- merge(dat, peak_data, by = c("ID", "decimal.values", "ID_label"), all.x = TRUE)
    dat$is_peak[is.na(dat$is_peak)] <- FALSE
  } else {
    dat$ID_label <- paste("ID:", id)
    dat$is_peak <- FALSE
  }
  
  return(dat)
}))

# Plot mit Facetten und Peak-Markierung
ggplot(all_data, aes(x = ID, y = decimal.values)) +
  geom_line(color = "blue") +
  geom_point(data = subset(all_data, is_peak), color = "red", size = 2) +
  facet_wrap(~ ID_label, scales = "free") +
  theme_minimal() +
  labs(x = " ", y = "Signal", title = " ")

```

Wie aus der Übersicht der Chromatogramme ersichtlich wird, erscheinen die Peaks vorallem im beta- und gamma-Bereich an unterschiedlichen Positionen. Auch variiert die Anzahl der Peaks je Chromatogramm. Meine ursprüngliche Idee die Peaks als Features zu verwenden, wird daher nicht funktionieren. Wenn für jeden Messpunkt die Signal-Höhe, Steigung, zweite Ableitung und Fläche unter der Kurve berechnet werden, dann stehen genügend Features zur Verfügung.

<br>





### Patientendaten


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-skimPatientData
#| tbl-cap: Datenüberblick

query <- "SELECT *
            FROM MeasurementData
            WHERE Tagesnummer IN ('2019.01.01.4339',
                                  '2019.01.02.0007', 
                                  '2019.01.02.5266');"
                     
                    
    pat.data <- dbGetQuery(con, query)
    

ft <- my_skim(pat.data)|> 
  select(skim_variable, skim_type) |>
  flextable() |>
  set_header_labels(skim_variable = "Variable",
                    skim_type = "Datentyp"#,
                    # n_missing = "Fehlende Werte",
                    # n = "Anzahl",
                    # numeric.mean = "Mittelwert",
                    # numeric.sd = "Standardabweichung",
                    # numeric.p25 = "25%-Quantil",
                    # numeric.p50 = "50%-Quantil",
                    # numeric.p75 = "75%-Quantil",
                    # numeric.p0 = "Minimum",
                    # numeric.p100 = "Maximum",
                    # numeric.hist = "Histogramm",
                    # factor.n_unique =" Anzahl Faktoren"
                    )|>
  autofit() |>
  bold(part = "header") |>
  align(align = "center", part = "all")
ft
```

#### Zusammenfassung {.unnumbered}
Da alle involvierten Prozesse der Datengeneration und der Datensammlung automatisiert und damit standardisiert sind, sind die Daten qualitativ hochwertig. Die Quantität der Daten mit `r nrow(EPcsv)` Datensätzen ist für einige unsupervised und auch supervised Model-Ansätze ausreichend, für Ansätze mit z. Bsp Tensor Flow sind es evtl. zu wenig Datensätze. 

## Untersuchen der Daten: Explorative Datenanalyse {.justify}

### Analyse der Befundtexte {.justify}

#### EP Befunde

Eventuell könnten die EP-Befundtexte als Vergleich zu den Vorhersagen der Modelle verwendet werden. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(stringr)
m.grad.count <- str_count(EPcsv$Bef.EP, regex("gradient", ignore_case = TRUE))
m.prot.count <- str_count(EPcsv$Bef.EP, regex("M-Protein", ignore_case = TRUE))
m.komp.count <- str_count(EPcsv$Bef.EP, regex("m-komponent", ignore_case = TRUE))
normal.count <- str_count(EPcsv$Bef.EP, regex("unauffällig", ignore_case = TRUE))
entf.count <- str_count(EPcsv$Bef.EP, regex("entfernt", ignore_case = TRUE))

```
In den Befundtexten kommt insgesamt das Wort <br>
"unauffällig" `r sum(normal.count)` mal vor. Das Wort<br>
"M-Protein" kommt `r sum(m.prot.count)`,<br>
"M-Komponente" `r sum(m.komp.count)`,<br>
"M-Gradient" `r sum(m.grad.count)` mal vor.


Auf den ersten Blick scheinen in den Daten `r sum(normal.count)` unauffällige Befunde vorzukommen,
bei insgesamt `r nrow(EPcsv)-sum(entf.count)` befundeten Chromatogrammen. Allerdings, wie sich unten zeigt, sind diese Befundtexte nicht standardisiert und sind für selbe Aussagen relativ variabel formuliert und enthalten Tippfehler. Sollten dieser Befundetexte zum Vergelich herangezogen werden, müssten sie genauer analysiert und klassifiziert werden.

##### 06.01.2025 Bereinigung und Tokenisierung der EP-Befundtexte
Das erste RF-Model, das auf den iFix-Befundtexten trainiert wurde, hat eine ROC_AUC von 0.83. 
Dies Klassifizierung der iFix-Befunde ist vermutlich nicht ganz sauber, es gibt Befunde, welche nicht korrekt klassifiziert wurden. Daher versuche ich in einer zweiten Runde sowohl die iFix-Befunde als auch die EP-Befunde besser zu bereiningen und zu klassifizieren.  
Nach Kleinschreibung, Entfernen von Satzzeichen, sowie Tokenisierung der Befundtexte ergibt sich folgende Häufigkeitsverteilung der Wörter in den iFix-Befundtexten:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-EP-Befundtexte
#| tbl-cap: Häufigkeitsverteilung der Wörter in den EP-Befundtexten

# Tokenisierung der EP-Befundtexte
library(tidytext)
library(stringr)
library(stopwords)
monate <- c(
  "Januar", "Jan",
  "Februar", "Feb",
  "März", "März",
  "April", "Apr",
  "Mai", "Mai",
  "Juni", "Jun",
  "Juli", "Jul",
  "August", "Aug",
  "September", "Sept",
  "Oktober", "Okt",
  "November", "Nov",
  "Dezember", "Dez",
  "Monat", "Monaten", "monaten"
) |> 
  paste(collapse = "|")

# stopwords anpassen, da in den tokens "nicht" enthalten bleiben soll
stopwords.olli <- setdiff(stopwords("de", "stopwords-iso"), c("nicht", 
                                                              "keine", 
                                                              "kein", 
                                                              "keinem", 
                                                              "keinen", 
                                                              "keiner", 
                                                              "keines", 
                                                              "ohne"))
stopwords.olli.col <- paste0("\\b(", paste(stopwords.olli, collapse = "|"), ")\\b")

EPcsv1 <- EPcsv |>
  mutate(
    Bef.EP_cleaned = gsub("\\([A-Za-zäöüÄÖÜ]+(/[A-Za-zäöüÄÖÜ]+)?\\)", "", Bef.EP),
    Bef.EP_cleaned = gsub("[0-9]+", "", Bef.EP_cleaned),
    #Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, monate, ""),
    Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, "[[:punct:]]", ""),
    Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, " +", " "),
    Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, "-", ""),
    Bef.EP_cleaned = str_squish(Bef.EP_cleaned)
  ) |> 
  unnest_tokens(Bef.EP_cleaned, Bef.EP_cleaned, token = "words", to_lower =TRUE, drop = FALSE) #|> 
  #filter(!Bef.EP_cleaned %in% stopwords.olli)

Bef.EP.freq <- EPcsv1 |> 
  count(Bef.EP_cleaned, sort = TRUE) |> 
  arrange(Bef.EP_cleaned)

ft1 <- Bef.EP.freq[1211:1300,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

ft2 <- Bef.EP.freq[1651:1740,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

ft3 <- Bef.EP.freq[1931:2020,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

ft4 <- Bef.EP.freq[611:700,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

# HTML-Ausgabe erstellen
html_output <- htmltools::browsable(
  htmltools::tagList(
    htmltools::tags$div(
      style = "display: flex; justify-content: space-between;",
      htmltools::tags$div(
        flextable::htmltools_value(ft1),
        style = "margin-right: 10px;"
      ),
      htmltools::tags$div(
        flextable::htmltools_value(ft2),
        style = "margin-right: 10px;"
      ),      
      htmltools::tags$div(
        flextable::htmltools_value(ft3)
      ),
      htmltools::tags$div(
        flextable::htmltools_value(ft4)
      )      
    )
  )
)

# HTML-Ausgabe anzeigen
#print(html_output, browse = TRUE)
html_output
```

##### Varianten des Wortes "unauffällig"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-EP-Befundtexte-unauffällig
#| tbl-cap: Varianten des Wortes "unauffällig"

# Berechnung der Levenshtein-Distanzen

Bef.EP.freq |> 
  mutate(Distanz = stringdist("unauffällig", Bef.EP_cleaned, method = "lv")) |> 
  filter(Distanz < 5)|>
  arrange(desc(n)) |>
  flextable() 

```
#### 06.01.2025 Zusammenfassung
[Auf den ersten Blick erscheinen die Befundtexte der EP-Chromatogramme ähnlich zusammengesetzt wie die Bfundtexte der Immunfixationen. Auch was Varianten und Tippfehler anbelangt. Hier sollte noch untersucht werden, in wie weit vorallem Befunde mit "unauffällig" zwischen EP- und iFix-Befundtexten übereinstimmen.]{style="color:#0000B8;font-weight:bold"} 

#### Immunfixation Befunde
Wie in [@elfertExpertlevelDetectionMproteins2024] beschrieben, brauchen wir für die Klassifizierung der EP-Chromatogramme in den Trainingsdaten eine "ground truth" welche durch eine andere Methode erstellt werden sollte. In unserem Setting sind wir auf die Befundtexte der Immunfixationen (iFix) angewiesen.
Daher ist es im folgenden wichtig diese gut zu untersuchen.

##### Bereinigung und Tokenisierung der Immunfixations-Befundtexte
Nach Kleinschreibung, Entfernen von Satzzeichen, sowie Tokenisierung der Befundtexte ergibt sich folgende Häufigkeitsverteilung der Wörter in den iFix-Befundtexten:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte
#| tbl-cap: Häufigkeitsverteilung der Wörter in den iFix-Befundtexten

# Tokenisierung der imFix-Befundtexte
library(tidytext)
library(stringr)
library(stopwords)
monate <- c(
  "Januar", "Jan",
  "Februar", "Feb",
  "März", "März",
  "April", "Apr",
  "Mai", "Mai",
  "Juni", "Jun",
  "Juli", "Jul",
  "August", "Aug",
  "September", "Sept",
  "Oktober", "Okt",
  "November", "Nov",
  "Dezember", "Dez",
  "Monat", "Monaten", "monaten"
) |> 
  paste(collapse = "|")

# stopwords anpassen, da in den tokens "nicht" enthalten bleiben soll
stopwords.olli <- setdiff(stopwords("de", "stopwords-iso"), c("nicht", 
                                                              "keine", 
                                                              "kein", 
                                                              "keinem", 
                                                              "keinen", 
                                                              "keiner", 
                                                              "keines", 
                                                              "ohne"))
stopwords.olli.col <- paste0("\\b(", paste(stopwords.olli, collapse = "|"), ")\\b")

EPcsv1 <- EPcsv |>
  mutate(
    Bef.ImFix_cleaned = gsub("\\([A-Za-zäöüÄÖÜ]+(/[A-Za-zäöüÄÖÜ]+)?\\)", "", Bef.ImFix),
    Bef.ImFix_cleaned = gsub("[0-9]+", "", Bef.ImFix_cleaned),
    #Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, monate, ""),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "[[:punct:]]", ""),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, " +", " "),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "-", ""),
    Bef.ImFix_cleaned = str_squish(Bef.ImFix_cleaned)
  ) |> 
  unnest_tokens(Bef.ImFix_cleaned, Bef.ImFix_cleaned, token = "words", to_lower =TRUE, drop = FALSE) #|> 
  #filter(!Bef.ImFix_cleaned %in% stopwords.olli)

Bef.ImFix.freq <- EPcsv1 |> 
  count(Bef.ImFix_cleaned, sort = TRUE) |> 
  arrange(Bef.ImFix_cleaned)

ft1 <- Bef.ImFix.freq[1461:1490,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

ft2 <- Bef.ImFix.freq[1611:1640,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

ft3 <- Bef.ImFix.freq[1931:1960,] |> 
  arrange(desc(n)) |>
  #head(20) |> 
  flextable()

# HTML-Ausgabe erstellen
html_output <- htmltools::browsable(
  htmltools::tagList(
    htmltools::tags$div(
      style = "display: flex; justify-content: space-between;",
      htmltools::tags$div(
        flextable::htmltools_value(ft1),
        style = "margin-right: 10px;"
      ),
      htmltools::tags$div(
        flextable::htmltools_value(ft2),
        style = "margin-right: 10px;"
      ),      
      htmltools::tags$div(
        flextable::htmltools_value(ft3)
      )
    )
  )
)

# HTML-Ausgabe anzeigen
#print(html_output, browse = TRUE)
html_output
```

Offensichtlich gibt es in den Befundtexten Wort-Varianten und Tippfehler. Daher werden einige Wörter, die in den Befundtexten vorkommen, auf ihre Ähnlichkeit zu wichtigen Begriffen wie "monoklonal", "M-Protein", "polyklonal", "akut-Phase", "immunreaktiv", "nachweisbar", "unauffällig", "Veränderung", "Vorbefund", "entfernt", "sistiert" überprüft.

##### Varianten des Wortes "monoklonal"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-monoklonal
#| tbl-cap: Varianten des Wortes "monoklonal"

# Berechnung der Levenshtein-Distanzen
Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("monoklon", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 5) |> 
  arrange(desc(n)) |>  
  flextable() 
```

##### Varianten des Wortes "M-Protein"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-M-Protein
#| tbl-cap: Varianten des Wortes "M-Protein"

# Berechnung der Levenshtein-Distanzen
Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("mprotein", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 4)|>
  arrange(desc(n)) |>
  flextable() 
```

##### Varianten des Wortes "polyklonal"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-polyklonal
#| tbl-cap: Varianten des Wortes "polyklonal"


# Berechnung der Levenshtein-Distanzen
Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("polyklon", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 6)|>
  arrange(desc(n)) |>
  flextable() 
```
##### Varianten des Wortes "akut-Phase"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-akut-Phase
#| tbl-cap: Varianten des Wortes "akut-Phase"

# Berechnung der Levenshtein-Distanzen
Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("akutphase", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 5)|>
  arrange(desc(n)) |>
  flextable() 
```

##### Varianten des Wortes "immunreaktiv"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-immunreaktiv
#| tbl-cap: Varianten des Wortes "immunreaktiv"


# Berechnung der Levenshtein-Distanzen
Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("immunreaktiv", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 5)|>
  arrange(desc(n)) |>
  flextable() 
```

##### Varianten des Wortes "nachweisbar"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-nachweisbar
#| tbl-cap: Varianten des Wortes "nachweisbar"


# Berechnung der Levenshtein-Distanzen

Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("nachweisbar", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 7)|>
  arrange(desc(n)) |>
  flextable() 

```

##### Varianten des Wortes "unauffällig"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-variationen-unauffällig
#| tbl-cap: Varianten des Wortes "unauffällig"


# Berechnung der Levenshtein-Distanzen

Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("unauffällig", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 5)|>
  arrange(desc(n)) |>
  flextable() 

```
##### Varianten des Wortes "Veränderung"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Var-Veränderung
#| tbl-cap: Varianten des Wortes "Veränderung"


# Berechnung der Levenshtein-Distanzen

Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("veränderung", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 5)|>
  arrange(desc(n)) |>
  flextable() 
```


##### Varianten des Wortes "Vorbefund"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Var-Vorbefund
#| tbl-cap: Varianten des Wortes "Vorbefund"


# Berechnung der Levenshtein-Distanzen

Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("vorbefund", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 4)|>
  arrange(desc(n)) |>
  flextable() 
```

##### Varianten des Wortes "entfernt"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Var-entfernt
#| tbl-cap: Varianten des Wortes "entfernt"


# Berechnung der Levenshtein-Distanzen

Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("entfernt", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 4)|>
  arrange(desc(n)) |>
  flextable() 
```

##### Varianten des Wortes "sistiert"
```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Var-sistiert
#| tbl-cap: Varianten des Wortes "sistiert"


# Berechnung der Levenshtein-Distanzen

Bef.ImFix.freq |> 
  mutate(Distanz = stringdist("sistiert", Bef.ImFix_cleaned, method = "lv")) |> 
  filter(Distanz < 4)|> 
  arrange(desc(n)) |>
  flextable() 
```

#### Kontext: Beziehung zwischen Wörtern, n-grams
Der Kontext der einzelenen Wörter ist wichtig. Z. Bsp. "kein M-Protein nachweisbar" ist ein anderer Kontext als "M-Protein nachweisbar". Daher ist es wichtig, dass diese Schlüsselwörter in ihrem Kontext betrachtet werden.

```{r, echo=TRUE, message=FALSE, warning=FALSE}

library(tidytext)

#Bef.ImFix.freq.ngram <- EPcsv |>
EPcsv2 <- EPcsv |>
  mutate(
    Bef.ImFix_cleaned = gsub("\\([^)]*\\)", "", Bef.ImFix),
    Bef.ImFix_cleaned = gsub("[0-9]+", "", Bef.ImFix_cleaned),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, monate, ""),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "[[:punct:]]", " "),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, " +", " "),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "-", "")#,
    #Bef.ImFix_cleaned = gsub(stopwords.olli.col, "", Bef.ImFix_cleaned)
    #Bef.ImFix_cleaned = str_squish(Bef.ImFix_cleaned)
  ) |> 
  unnest_tokens(trigram, Bef.ImFix_cleaned, token = "ngrams", n = 3, to_lower =TRUE, drop = FALSE) |>
  filter(!is.na(trigram))  |> 
  separate(trigram, c("word1", "word2", "word3"), sep = " ")  #|> 
  # filter(!word1 %in% stopwords.olli,
  #        !word2 %in% stopwords.olli,
  #        !word3 %in% stopwords.olli)
#  filter(!Bef.ImFix_cleaned %in% stopwords.olli)#|> 
#  arrange(Bef.ImFix, Bef.ImFix_cleaned)#|> 
#  count(Bef.ImFix_cleaned, sort = TRUE)
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-kotext
#| tbl-cap: Kontextanalyse in den iFix-Befundtexten
#show the first 50 lines from EPcsv2, only the columns Bef.ImFix and Bef.ImFix_cleaned
EPcsv2 |> 
  select(Bef.ImFix, word1, word2, word3) |> 
  head(10) |> 
  flextable()
```

Weiter werden die häufigsten n-Gramme in den Befundtexten untersucht:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-ngram
#| tbl-cap: Häufigkeitsverteilung der n-Gramme in den iFix-Befundtexten
EPcsv2 |> 
   na.omit() |>
   count(word1, word2, word3, sort = TRUE) |> 
   arrange(desc(n)) |> 
   head(20) |> 
   flextable()
```

Im weiteren werden Kombinationen mit dem Wort "nicht" & "ohne" untersucht:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-nicht
#| tbl-cap: Kombinationen mit "nicht" in den iFix-Befundtexten
EPcsv2 |> 
   na.omit() |>
   mutate(distance = stringdist("nicht", word1, method = "lv")) |>
   filter(distance < 2) |>
   count( word1, word2, word3, sort = TRUE) |> 
   arrange(desc(n)) |> 
   head(20) |> 
   flextable()
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-ohne
#| tbl-cap: Kombinationen mit "ohne" in den iFix-Befundtexten


EPcsv2 |> 
   na.omit() |>
   mutate(distance = stringdist("ohne", word1, method = "lv")) |>
   filter(distance < 2) |>
   count( word1, word2, word3, sort = TRUE) |> 
   arrange(desc(n)) |> 
   head(20) |> 
   flextable()
```

Im weiteren werden Kombinationen mit den Wörtern "keine" & "kein" untersucht:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-keine
#| tbl-cap: Kombinationen mit "keine" in den iFix-Befundtexten


EPcsv2 |> 
   na.omit() |>
   mutate(distance = stringdist(c("keine", "kein"), word1, method = "lv")) |>
   filter(distance < 1) |>
   count( word1, word2, word3, sort = TRUE) |> 
   arrange(desc(n)) |> 
   head(20) |> 
   flextable()
```

Kombinationen mit "unauffällig"

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-unauffällig
#| tbl-cap: Kombinationen mit "unauffällig" in den iFix-Befundtexten


EPcsv2 |> 
   na.omit() |>
   mutate(distance = stringdist("unauffällig", word1, method = "lv")) |>
   filter(distance <= 3) |>
   count( word1, word2, word3, sort = TRUE) |> 
   arrange(desc(n)) |> 
   head(30) |> 
   flextable()
```

Es scheint auch informativ die Häufigkeiten der etwas bereinigten Befundtexte zu untersuchen:

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-Stoppwörter
#| tbl-cap: Häufigkeitsverteilung der bereinigten iFix-Befundtexten zur Analyse von Stoppwörtern
#Bef.ImFix.freq.ngram <- 
EPcsv2 |> 
  count(Bef.ImFix_cleaned, sort = TRUE) |> 
  arrange(desc(n)) |>
  head(50) |>
  flextable() |> 
  width(j = 1, width = 6.5)
  
```
Daraus wird klar, dass es viele Wörter gibt, die in den Befundtexten vorkommen, die keine relevante Information für eine spätere Klassifizierung transportieren. z.Bsp "weiterhin", "des", "bekannten", "vom", "Typ". \b
Es ist zu überlegen, ob diese als Stoppwörter in der Datapreparation entfernt werden.

#### Analyse der iFix-Befundtext ohne Stoppwörter {.justify}

##### Anlegen der Stoppwörterliste

```{r, echo=TRUE, message=FALSE, warning=FALSE} 
# Hinzufügen von Stopwörtern wie "weiterhin" zu stopwords.olli
ad.string <- c("ist die quantitative Bestimmung der aus der aktuellen Serumprobe und oder eine Verlaufskontrolle zu empfehlen Homogene Unspezifischer Befund vereinbar mit einer sowie der isolierten einer äusserst diskreten und diffusen in den Spuren für sicheren Je nach klinischem Kontext ist eine Verlaufskontrolle zu empfehlen  und bedingt einen modifizierten Ansatz Das initial berichtete endogene Weiterhin schwacher des vorbekannten sowie der zusätzlichen diskreten Zonierungen in den Spuren wesentliche des stark ausgeprägten Mobilität sowie des sehr schwach ausgeprägten leicht einer äusserst diskreten und diffusen Befund mit einer schwach ausgeprägten diskret diffusen bekannten Bei unklarer Ätiologie Verlaufskontrolle diskreter Bei Ätiologie Verlaufskontrolle Typ Verlaufskontrolle B RGB initialen klin")

stopwords.olli <- c(stopwords.olli, ad.string |>
  str_split(" ") |>
  unlist()) |>
  tolower() |>
  unique() |>
  setdiff("") |>
  sort()

stopwords.olli
```


```{r, echo=TRUE, message=FALSE, warning=FALSE} 
stopwords.olli.col <- paste0("\\b(", paste(stopwords.olli, collapse = "|"), ")\\b")
```



```{r, echo=TRUE, message=FALSE, warning=FALSE}
EPcsv2 <- EPcsv |>
  mutate(
    Bef.ImFix_cleaned = gsub("\\([^)]*\\)", "", Bef.ImFix),
    Bef.ImFix_cleaned = gsub("[0-9]+", "", Bef.ImFix_cleaned),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, monate, ""),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "[[:punct:]]", " "),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, " +", " "),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "\\bmonoklonale?n?s?\\b", "M"),
    Bef.ImFix_cleaned = str_replace_all(Bef.ImFix_cleaned, "\\bM Proteine?n?s?\\b", "MProtein"),
    Bef.ImFix_cleaned = str_squish(Bef.ImFix_cleaned),
    Bef.ImFix_cleaned = tolower(Bef.ImFix_cleaned),
    Bef.ImFix_cleaned = gsub(stopwords.olli.col, "", Bef.ImFix_cleaned),
    Bef.ImFix_cleaned = str_squish(Bef.ImFix_cleaned)
   ) #|> 
  # unnest_tokens(trigram, Bef.ImFix_cleaned, token = "ngrams", n = 3, to_lower =TRUE, drop = FALSE) |>
  # filter(!is.na(trigram))  |> 
  # separate(trigram, c("word1", "word2", "word3"), sep = " ")
  
```

Für die Analyse der Häufigkeiten der Befundtexte, werden die Stopwörter entfernt, es werden aber auch Synonyme zusammengefasst. Z.Bsp "monoklonal", "monoklonale Proteine", "monoklonalen Proteinen", "monoklonales Proteins", "M-Protein", "M-Proteins", etc werden zu "mprotein" zusammengefasst.

```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-iFix-Befundtexte-ohne-Stoppwörter
#| tbl-cap: Häufigkeitsverteilung der bereinigten iFix-Befundtexten ohne Stoppwörter


#Bef.ImFix.freq.ngram <- 
EPcsv2 |> 
  count(Bef.ImFix_cleaned, sort = FALSE) |> 
  arrange(desc(n)) |>
  head(50) |>
  flextable() |> 
  width(j = 1, width = 6.5)
  
```

<!-- # ```{r, echo=TRUE, message=FALSE, warning=FALSE} -->
<!-- # # Tokenisierung der EP-Befundtexte -->
<!-- # library(tidytext) -->
<!-- # library(stringr) -->
<!-- # library(stopwords) -->
<!-- # EPcsv1 <- EPcsv1 |> -->
<!-- #   mutate( -->
<!-- #     # Bef.EP_cleaned = str_to_lower(Bef.EP, locale = "de_CH"), -->
<!-- #     Bef.EP_cleaned = gsub("\\([A-Z]{3}\\)", "", Bef.EP), -->
<!-- #     # Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, "[[:punct:]]", ""), -->
<!-- #     Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, "[[:punct:]]", ""), -->
<!-- #     # Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, " +", " "), -->
<!-- #     Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, " +", " "), -->
<!-- #     Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, "-", ""), -->
<!-- #     # Bef.EP_cleaned = str_replace_all(Bef.EP_cleaned, " +", " "), -->
<!-- #     # Bef.EP_cleaned = str_squish(Bef.EP_cleaned, " +", " "), -->
<!-- #     Bef.EP_cleaned = str_squish(Bef.EP_cleaned) -->
<!-- #   ) |>  -->
<!-- #   filter(!Bef.EP_cleaned %in% stopwords("de"))|>  -->
<!-- #   unnest_tokens(Bef.EP_cleaned, Bef.EP_cleaned, token = "words", to_lower = TRUE, drop = FALSE)  -->
<!-- # ``` -->

#### Zusammenfassung der iFix-Befundtext-Analysen {.justify}

```{r, echo=T, message=FALSE, warning=FALSE}
library(stringr)

# Definieren der zu entfernenden Phrasen
phrasen <- c("ohne wesentliche Veränderung", 
             "keine wesentliche Veränderung", 
             "ohne signifikante Veränderung", 
             "keine signifikante Veränderung", 
             "Hinweis: Bitte markieren Sie die Analyse Immunfixation auf dem Auftragsformular  nicht", 
             "Keine Veränderung zum Vorbefund.", 
             "keine wesentlichen Veränderungen", 
             "Keine wesentlichen Veränderungen", 
             "keine Veränderung gegenüber dem", 
             "Keine wesentliche Veränderung", 
             "Keine Veränderung im Vergleich zum", 
             "Keine signifikante Veränderung", 
             "keine Veränderungen zum", 
             "Keine signifikanten Unterschiede", 
             "keine wesentlichen Änderungen", 
             "Keine wesentlichen Änderungen", 
             "Keine signifikant Veränderung", 
             "keine signifikante Änderung", 
             "Keine wesentliche Änderungen", 
             "Keine wesenstliche Veränderung", 
             "Keine Veränderungen zum", 
             "Befund ohne wesentliche qualitative Veränderung", 
             "Keine wesentliche Änderung", 
             "keine wesentliche Änderung", 
             "Keine signifikanten Veränderungen", 
             "keine signifikanten Veränderungen", 
             "ohne Veränderung",
             "unverändert gegenüber dem Vorbfund",
             "Kein signifikanter Unterschied zum vorherigen",
             "Im Vergleich zum Vorbefund unverändert")


# Erstellen eines regulären Ausdrucks, der alle Phrasen abdeckt
vorbef <- paste(phrasen, collapse = "|")

vorb.count <- str_count(EPcsv$Bef.ImFix, regex(vorbef, ignore_case = T))
```
[In den iFix-Befundtexten kommen Synonyme, Rechtschreibfehler, Gross- & Kleinschreibung, Stopwörter, Daten, Abkürzungen und Satzzeichen vor. Nach deren Bereinigung sollten die relevanten Informationen für die Klassifizierung der Chromatogramm-Daten leichter zu extrahieren sein.]{style="color:#00008B;font-weight:bold"}<br>
[In den Immunfixationen kommen insgesamt `r sum(vorb.count, na.rm = T)` Verweise auf historische Befunde vor, zu denen im Vergleich keine Veränderung erkennbar war. Diese Verweise bringen also Wörter wie "keine" und "ohne" in die Befundtexte mit ein. Diese sind jedoch in einem anderen Zusammenhang wie z. Bsp. "keine monoklonale Bande erkennbar". Diese müssen also unterschieden werden.]{style="color:#00008B;font-weight:bold"}<br>
[Die Auswertung von tri-Grams könnte evtl dabei helfen, diese Varianten zu unterscheiden.]{style="color:#00008B;font-weight:bold"}


<!-- ```{r, echo=T, eval=FALSE, message=FALSE, warning=FALSE} -->
<!-- # Funktion zum Entfernen der Phrase -->
<!-- # entferne_phrasen <- function(text) { -->
<!-- #   # Entfernen der definierten Phrasen -->
<!-- #   text <- str_remove_all(text, vorbef) -->
<!-- #   return(text) -->
<!-- # } -->
<!-- #  -->
<!-- # # Anwenden der Funktion auf den gesamten Vektor -->
<!-- # EPcsv1 <- EPcsv |>  -->
<!-- #   mutate(Bef.ImFix = sapply(Bef.ImFix, entferne_phrasen)) -->

<!-- # EPcsv1$Bef.ImFix <- sapply(EPcsv$Bef.ImFix, entferne_phrasen) -->


<!-- EPcsv1 <- EPcsv |> -->
<!--   mutate( -->
<!--     pos.string.iFix = case_when( -->
<!--       is.na(Bef.ImFix) ~ NA,  # Falls Bef.ImFix NA ist, wird suspicious NA -->
<!--       grepl("\\b(M-)?Protein(e|s|er|en)?\\b|\\b(mono)?klonal(e|es|er|en)?\\b|Bande|Zonierung|Zonen|M-Protein|Para\\w|Inhomogen\\w|Unregelmässig\\w|monolonal\\w|monnolonal\\w|Gradienten\\w|Gammopathie\\w|M-Komponente|monoklonlen|biklonal|M-Gradienten|klonalen|monoklonalen", Bef.ImFix, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ), -->
<!--     neg.iFix = case_when( -->
<!--       is.na(Bef.ImFix) ~ NA,  # Falls Bef.ImFix NA ist, wird neg.iFix NA -->
<!--       grepl("unauffällig|unaufällig|unauffälllig|unaufffällig|unaufffälllig|unuaffällig|ünauffällig|unauffällg|unauffälig|unaufälig|negativ|unauffàllig|uanuffällig|uanauffällig", Bef.ImFix, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ), -->
<!--     polyklon.string.iFix = case_when( -->
<!--       is.na(Bef.ImFix) ~ NA,  # Falls Bef.ImFix NA ist, wird neg.phrase NA -->
<!--       grepl("polyklon|Verstärkung|verstärkt|poliklon", Bef.ImFix, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ), -->
<!--     neg.string.iFix = case_when( -->
<!--       is.na(Bef.ImFix) ~ NA,  # Falls Bef.ImFix NA ist, wird neg.phrase NA -->
<!--       grepl("nicht|kein\\w|ohne|kein", Bef.ImFix, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ), -->
<!--     vorb.string.iFix = case_when( -->
<!--       is.na(Bef.ImFix) ~ NA,  # Falls Bef.ImFix NA ist, wird neg.phrase NA -->
<!--       grepl(vorbef, Bef.ImFix, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ), -->
<!--     no.string.iFix = case_when( -->
<!--       is.na(Bef.ImFix) ~ NA,  # Falls Bef.ImFix NA ist, wird neg.phrase NA -->
<!--       grepl("folgt|entfernt|SISTIERT|#NAME", Bef.ImFix, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ), -->
<!--     neg.EP = case_when( -->
<!--       is.na(Bef.EP) ~ NA,  # Falls Bef.EP NA ist, wird EP.neg NA -->
<!--       grepl("unauffällig", Bef.EP, ignore.case = TRUE) ~ 1, -->
<!--       TRUE ~ 0 -->
<!--     ) -->
<!--   ) -->

<!-- df <- as.data.frame(table(EPcsv1$neg.iFix, EPcsv1$neg.string.iFix, EPcsv1$pos.string.iFix,EPcsv1$polyklon.string.iFix, EPcsv1$vorb.string.iFix, EPcsv1$no.string.iFix)) -->
<!-- colnames(df) <- c("neg.iFix", "neg.string.iFix", "pos.string.iFix", "polyklon.string.iFix", "VerwVorbefund", "KeinText", "Anzahl") -->
<!-- flextable(df) -->

<!-- # save df as excel file -->
<!-- # write.xlsx(df, "Befundanalyse.xlsx") -->

<!-- # string.analys <- EPcsv1 |>  -->
<!-- #   summarise( -->
<!-- #     poitive.iFix = sum(suspicious.iFix == 1 & neg.phrase.iFix == 0, na.rm = TRUE), -->
<!-- #     neg.phrase.iFix = sum(suspicious.iFix == 1 & neg.phrase.iFix == 1 | suspicious.iFix == 0 & neg.phrase.iFix == 0, na.rm = TRUE), -->
<!-- #     neg.EP = sum(neg.EP == 1, na.rm = TRUE), -->
<!-- #     neg.EP.pos.iFix = sum(neg.EP == 1 & suspicious.iFix == 1, na.rm = TRUE), -->
<!-- #     other = sum(suspicious.iFix == 0 & neg.phrase.iFix == 1, na.rm = TRUE) -->
<!-- #   ) -->

<!-- # EPcsv.red <- EPcsv1 |>  -->
<!-- #   filter(neg.EP == 1 & suspicious.iFix == 1) |>  -->
<!-- #   select(ID, Bef.EP, Bef.ImFix, suspicious.iFix, neg.phrase.iFix, neg.EP) -->
<!-- #  -->
<!-- #positive.iFix.count <- EPcsv1 |> -->
<!--   filter(pos.string.iFix == 1 & neg.iFix == 0) |> -->
<!--   nrow() -->

<!--  #negative.iFix.count <- EPcsv1 |>  -->
<!--    filter(pos.string.iFix == 1 & neg.string.iFix == 1 | pos.string.iFix == 0 & neg.string.iFix == 0 | neg.iFix == 0)  |>  -->
<!--    nrow()  -->
<!-- #  -->
<!-- other.count <- EPcsv1 |> -->
<!--   filter(pos.string.iFix == 0 & neg.string.iFix == 1 ) |> -->
<!--   nrow() -->

<!-- # neg.EP.count <- EPcsv1 |>  -->
<!-- #   filter(neg.EP == 1) |>  -->
<!-- #   nrow() -->
<!-- #  -->
<!-- # neg.EP.pos.iFix <- EPcsv1 |>  -->
<!-- #   filter(neg.EP == 1 & suspicious.iFix == 1) |>  -->
<!-- #   nrow() -->
<!-- #   -->
<!-- ``` -->



```{r , echo=TRUE, eval=FALSE,message=FALSE, warning=FALSE}
# print(head(EPcsv, 10))
# print(glimpse(EPcsv))
ft <-  flextable(my_skim(EPcsv1))
ft
```




#### 06.01.2025 Vergleich der EP- und iFix-Befundtexte {.justify}
Das wichtiste Wort um normale von auffälligen EP-Chromatogrammen durch die BEfundtexte zu unterscheiden ercheint das Wort "unauffällig" zu sein. Hier wird vergleichen wie oft dieses Wort in den EP- und iFix-Befunden vorkommt und wie gross die Schnittmenge ist.

Anzahl der "unauffällig" in den EP- und iFix-Befunden
```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-unauffällig-EPB-iFix
#| tbl-cap: Anzahl der "unauffällig" in den EP- und iFix-Befunden
# Anzahl der "unauffällig" in den EP- und iFix-Befunden
library(dplyr)
library(flextable)

EPcsv |> 
  summarize(
    Möglichkeit = c(
      "Nur in Bef.EP",
      "Nur in Bef.ImFix",
      "In beiden Spalten"
    ),
    Anzahl = c(
      sum(grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
            !grepl("unauffällig", Bef.ImFix, ignore.case = TRUE)),
      sum(!grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
            grepl("unauffällig", Bef.ImFix, ignore.case = TRUE)),
      sum(grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
            grepl("unauffällig", Bef.ImFix, ignore.case = TRUE))
    )
  ) |> 
  flextable()
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
#| label: tbl-Vergleich-EPB-iFix
#| tbl-cap: Vergleich unauffälliger Befunde der EP- und iFix-Befundtexte
library(dplyr)
library(flextable)

# Für jede der drei Kategorien 50 Zeilen auswählen
#result <- bind_rows(
ft1 <-   EPcsv |>
    filter(grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
             !grepl("unauffällig", Bef.ImFix, ignore.case = TRUE)) |>
    select(ID, Bef.EP, Bef.ImFix) |>
    head(50) |>
    mutate(Kategorie = "Nur in Bef.EP") |> #,
    flextable()
  
ft2 <-   EPcsv |>
    filter(!grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
             grepl("unauffällig", Bef.ImFix, ignore.case = TRUE)) |>
    select(ID, Bef.EP, Bef.ImFix) |>
    head(50) |>
    mutate(Kategorie = "Nur in Bef.ImFix") |> #,
    flextable()
  
ft3 <-   EPcsv |>
    filter(grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
             grepl("unauffällig", Bef.ImFix, ignore.case = TRUE)) |>
    select(ID, Bef.EP, Bef.ImFix) |>
    head(50) |>
    mutate(Kategorie = "In beiden Spalten") |> #,     
    flextable()

ft4 <-   EPcsv |>
    filter(grepl("unauffällig", Bef.EP, ignore.case = TRUE) & 
             grepl("M-Protein", Bef.ImFix, ignore.case = TRUE)) |>
    select(ID, Bef.EP, Bef.ImFix) |>
    head(50) |>
    mutate(Kategorie = "Unauffällig + MProt") |> #,     
    flextable()
#)

# Flextable erstellen
#flextable(result[, c("Kategorie", "Bef.EP", "Bef.ImFix")])

# HTML-Ausgabe erstellen
html_output <- htmltools::browsable(
  htmltools::tagList(
    htmltools::tags$div(
      style = "display: flex; justify-content: space-between;",
      htmltools::tags$div(
        flextable::htmltools_value(ft1),
        style = "margin-right: 10px;"
      ),
      htmltools::tags$div(
        flextable::htmltools_value(ft2),
        style = "margin-right: 10px;"
      ),      
      htmltools::tags$div(
        flextable::htmltools_value(ft3)
      )
    ),      
      htmltools::tags$div(
        flextable::htmltools_value(ft4)
      )
  )
)

# HTML-Ausgabe anzeigen
#print(html_output, browse = TRUE)
html_output

```


#### 06.01.2025 Zusammenfassung {.justify}
[Die EP-Befunde mit "unauffällig" scheinen konsistenter und einheitlicher als die iFix-Befundberichte mit "unauffällig" zu sein. Im zweiten random forest Model werde ich die Klassifizierung "unauffällig" und "auffällig" auf Basis der EP-Befunde durchführen.]{style="color:#00008B;font-weight:bold"}
<!-- ### Chromatogramm Daten -->

<!-- ```{r, echo=FALSE, message=FALSE, warning=FALSE} -->
<!-- hex.string <- EPcsv$curve[EPcsv$ID == 1691] -->

<!-- # Split the string into hexadecimal parts -->
<!-- hex.parts <- substring(hex.string, seq(1, nchar(hex.string), 4), seq(4, nchar(hex.string), 4)) -->

<!-- # Convert each hex part to decimal -->
<!-- decimal.values <- sapply(hex.parts, function(x) as.integer(paste0("0x", x))) -->

<!-- # dataframe with hexadecimal and decimal values -->
<!-- decimal.values <- as.data.frame(decimal.values) -->
<!-- decimal.values$hex.parts <- hex.parts -->
<!-- decimal.values$ID <- seq_len( nrow(decimal.values) ) |> rev() -->

<!-- # delete rows with decimal values >10000 -->
<!-- decimal.values <- decimal.values[decimal.values$decimal.values < 10000,] -->

<!-- plot(decimal.values ~ ID, data = decimal.values, type = "p", pch = 20, col = "blue", lwd = 2, xlab = "ID", ylab = "signal", main = "protein electrophoresis chromatogram") -->
<!-- ``` -->


## Überprüfen der Datenqualität {.justify}

Die quantitativen Datensätze sind alle einheitlich, da automatisiert aufgezeichnet. 
Von den `r as.integer(nrow(EPcsv))` Datensätze fehlen bei `r as.integer(sum(is.na(EPcsv$curve)))` die Chromatographie-Daten. Diese könnten bei der Datenpreparation ausgeschlossen werden.  

Die Chromatographie Daten wurden bis `r as.Date(substr(max(EPcsv$TaNu), 1, 10), format = "%Y.%m.%d")` im vorliegenden Datensatz gespeichert. Die Daten von `r as.Date(substr(max(EPcsv$TaNu), 1, 10), format = "%Y.%m.%d")` bis `r Sys.Date()` könnten noch hinzugefügt werden.

Die Befundtexte, die wichtig für die Klassifizierung sind, sind wenig standardisiert. Es gibt viele Synonyme und Rechtschreibfehler. Daher ist es wichtig, dass die Befundtexte gut bereinigt werden.

